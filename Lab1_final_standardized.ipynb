{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release note\n",
    "This is an updated version of the Jupyter notebook for the first lab. We have updated our CS4065 utilities to make dataset loading easier and more uniform for the coming weeks.\n",
    "\n",
    "If you already completed this assignment, no worries, in terms of content nothing changed. If you want to keep working on a local installation, please verify your installation using the instructions on Blackboard though.\n",
    "\n",
    "Otherwise, you are reaching this assignment using the provided lab VM, and you are good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "In today's lab, we will look into image similarity, considering a dataset of film posters which you can download from Blackboard.\n",
    "\n",
    "By using this notebook server format, you have the assignments and instructions in one file, and you can dynamically update your code in your browser to play around with various parameters to see the effect.\n",
    "\n",
    "As final deliverable to demonstrate your successful completion, please submit two text files through https://www.dropbox.com/request/KZGwmMXV9YeoNh1goKR5:\n",
    "* [1] A text file named [YourName_ranking.txt] containing a top-10 ranking for a feature-similarity measure configuration you considered to be strong. Please specify the file according to the format indicated in the last cell on this page.\n",
    "* [2] A text file named [YourName_reflection.txt] in which you explain why you thought this ranking was strong, and indicate what visual features you would wish to use or develop if you would like to do film genre classification based on visual poster features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you have the latest version of the utility code and data?\n",
    "\n",
    "### If you work on the VM\n",
    "To ensure you have the latest version of the code, please log into the VM.\n",
    "\n",
    "You can login through SSH or through the VirtualBox window [login: student, password: 3m3mCL4b];\n",
    "also see the instructions at https://docs.google.com/document/d/1K5Y53Jgc0pPVobLJXP2ynOjRC0eSxmHb37JuxuOdHPs/edit?ts=571f6c6f if you don't know how to do this.\n",
    "\n",
    "In your terminal window, do the following from your home directory:\n",
    "\n",
    "<code>$ cd ~/pylib/cs4065 \n",
    "$ git pull</code>\n",
    "\n",
    "The poster_images folder with movie posters already is on the VM and configured properly.\n",
    "\n",
    "If the repository was not already up to date, please restart the kernel through the top menu (Kernel > Restart).\n",
    "\n",
    "### If you work locally\n",
    "If you didn't do so yet, import the lab utility modules from the https://github.com/mmc-tudelft/cs4065 project\n",
    "by executing:\n",
    "\n",
    "<code>$ git clone https://github.com/mmc-tudelft/cs4065.git</code>\n",
    "\n",
    "or if you already had this repository cloned, perform a\n",
    "\n",
    "<code>$ git pull</code>\n",
    "\n",
    "to update your code (you may have to execute <code>git stash</code> beforehand, if you modified <code>datasets.py</code>). \n",
    "\n",
    "**Please make sure this notebook file is located in the above folder, created with the clone command.**\n",
    "\n",
    "As for where to put the poster_images data: instead of modifying the <code>datasets.py</code> file, we will more sustainably indicate a dataset directory as follows (if you followed the Blackboard instructions, you should actually have done this already as part of the reverification of your installation): \n",
    "* Choose a path to the folder in which you would like all lab datasets to be downloaded.\n",
    "* Within the cs4065 repository folder, copy <code>config-sample.py</code> to a file named <code>config.py</code> (in that same directory).\n",
    "* Open <code>config.py</code> and replace <code>/home/student/data/cs4065</code> by <code>/absolute/path/to/your/dataset/folder</code> .\n",
    "\n",
    "For this first lab assignment, download the poster_images dataset from Blackboard, and unpack the zipped file to your <code>/absolute/path/to/your/dataset/folder</code>  folder. In future assignments, we will as much as possible automatically retrieve and unpack datasets here.\n",
    "\n",
    "Then restart the kernel through the top menu (Kernel > Restart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get you going!\n",
    "We will first import all necessary Python modules. Hit 'ctrl-enter' (or the 'run cell button') to execute the import statements in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import standard Python modules.\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "# Import extra Python modules.\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# Make matplotlib plot inline\n",
    "%matplotlib inline \n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you are working on your local machine and followed the Blackboard instructions,\n",
    "# the 'path/to/cs4065' should already be appended to your PYTHONPATH.\n",
    "# If this isn't the case, please refer to the online instructions!\n",
    "\n",
    "from datasets import CS4065_Dataset\n",
    "from cvtools import ipynb_show_color_histogram\n",
    "from cvtools import ipynb_show_cv2_image\n",
    "from cvtools import ipynb_show_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to set some parameters to ensure compatibility with various possible OpenCV versions (note that future assignments are not guaranteed to support OpenCV 3 syntax; also see BB for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters.\n",
    "try:\n",
    "  _CV2_BGR2HSV = cv2.cv.CV_BGR2HSV\n",
    "except:\n",
    "  _CV2_BGR2HSV = cv2.COLOR_BGR2HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's start!\n",
    "Let's first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset of images.\n",
    "poster_images = CS4065_Dataset.get_poster_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now print the length of our poster array, and the path to the first image referred to in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(poster_images))  # Number of images.\n",
    "print(poster_images[0])  # Path to the first image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what this image looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and show an image.\n",
    "image = cv2.imread(poster_images[0])\n",
    "ipynb_show_cv2_image(image) # OpenCV is not as trivial with image display, but you can use our utility code for this.\n",
    "print(np.shape(image)) # We verify the dimensions of this image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "What do these three printed numbers indicate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing on the image\n",
    "As you heard in the lecture, an image can be seen as a matrix. Let's modify some of the matrix values to draw rectangles in the poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's modify the image a little bit (see http://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html).\n",
    "image_modified = image.copy()  # Don't forget to copy the image.\n",
    "cv2.rectangle(image_modified, (60, 175), (120, 230), (0, 0, 255))  # OpenCV works with the BGR format (by default).\n",
    "cv2.rectangle(image_modified, (110, 110), (180, 195), (255, 0, 0))\n",
    "\n",
    "ipynb_show_cv2_image(image_modified, figsize=(10, 10))  # Use figsize to change the plot dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Modify and rerun the code above to draw differently colored rectangles at different places in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "Now, we continue extracting features from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract global histogram features from images.\n",
    "\n",
    "# First, define a function that extracts RGB histograms.\n",
    "def compute_bgr_histogram(image, mask=None):\n",
    "  histogram = cv2.calcHist(\n",
    "      [image],  # List of images (in our case, just one).\n",
    "      [0, 1, 2],  # List of channels to analyze.\n",
    "      mask,  # Mask (optional).\n",
    "      [8, 8, 8],  # Number of bins per channel.\n",
    "      [0, 256, 0, 256, 0, 256]  # Range of each channel.\n",
    "  )\n",
    "  histogram_normalized = histogram.copy()\n",
    "  cv2.normalize(histogram, histogram_normalized)\n",
    "  return np.array(histogram_normalized).flatten()\n",
    "  # return cv2.normalize(histogram).flatten()  # We want the histogram as a vector.\n",
    "\n",
    "\n",
    "# Let's add a function for HSV histograms as well.\n",
    "def compute_hsv_histogram(image, mask=None):\n",
    "  hsv_image = cv2.cvtColor(image, _CV2_BGR2HSV)\n",
    "  histogram = cv2.calcHist([hsv_image], [0, 1, 2], mask, [8, 8, 8], [0, 180, 0, 256, 0, 256]) # Note that H goes from 0 to 180.\n",
    "  histogram_normalized = histogram.copy()\n",
    "  cv2.normalize(histogram, histogram_normalized)\n",
    "  return np.array(histogram_normalized).flatten()\n",
    "\n",
    "\n",
    "# Again, we have to do some parameter configuration to ensure compatibility.\n",
    "try:\n",
    "  _CV2_BGR2HSV = cv2.cv.CV_BGR2HSV\n",
    "except:\n",
    "  _CV2_BGR2HSV = cv2.COLOR_BGR2HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "Now, looking at the code in the cell above, write an own function in the cell below that computes a histogram only using the H and S values of the image.\n",
    "\n",
    "*When writing your code, consider the amount of bins in your histogram. How many bins were used per channel in the sample functions above? How many bins were used in total for the histogram? Can you write a function using the same overall amount of bins?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And another one for HS histograms (we are not obliged to use all the channels).\n",
    "def compute_hs_histogram(image, mask=None):\n",
    "  # Code here\n",
    "  pass\n",
    "\n",
    "# Compute histograms.\n",
    "bgr_histogram = compute_bgr_histogram(image)\n",
    "print(np.shape(bgr_histogram))\n",
    "hsv_histogram = compute_hsv_histogram(image)\n",
    "print(np.shape(hsv_histogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Also compute your HS histogram: uncomment the lines below.\n",
    "#hs_histogram = compute_hs_histogram(image)\n",
    "#print(np.shape(hs_histogram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show histograms.\n",
    "_, image_filename = os.path.split(poster_images[0])\n",
    "ipynb_show_color_histogram(bgr_histogram, '<%s> BGR histogram' % image_filename)\n",
    "ipynb_show_color_histogram(hsv_histogram, '<%s> HSV histogram' % image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Also do this for your HS histogram.\n",
    "#ipynb_show_color_histogram(hs_histogram, '<%s> HS histogram' % image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature computation for the whole dataset\n",
    "How to these features influence the way in which images are related to one another?\n",
    "\n",
    "We will compute features for each of our items in the dataset, and then build a (dis)similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's compare all the images by building a feature matrix and a (dis-)similarity one.\n",
    "\n",
    "# We will try different features.\n",
    "feature_extractors = {\n",
    "    'BGRhist': (compute_bgr_histogram, 512),  # Pointer to function, feature space dimensionality.\n",
    "    'HSVhist': (compute_hsv_histogram, 512),\n",
    "    # uncomment the line below for your own HS histogram\n",
    "    #'HShist': (compute_hs_histogram, 144),\n",
    "}\n",
    "\n",
    "# Let's compute the feature matrices.\n",
    "number_of_images = len(poster_images)\n",
    "feature_matrices = {}\n",
    "\n",
    "# We iterate over the various features and compute the feature vectors.\n",
    "for feature_name in feature_extractors:\n",
    "  print('computing %s feature matrix' % feature_name)\n",
    "  (feature_extractor, feature_space_dimensionality) = feature_extractors[feature_name]\n",
    "\n",
    "  # Initialize matrix.\n",
    "  feature_matrices[feature_name] = np.zeros(\n",
    "      (number_of_images, feature_space_dimensionality), np.float32)\n",
    "\n",
    "  # Compute feature vectors.\n",
    "  for index, image_path in enumerate(poster_images):\n",
    "    image = cv2.imread(image_path)\n",
    "    feature_matrices[feature_name][index, :] = feature_extractor(image)\n",
    "\n",
    "  # Show statistics.\n",
    "  print(' - size', np.shape(feature_matrices[feature_name]))\n",
    "  print(' - min: %.3f' % np.min(feature_matrices[feature_name]))\n",
    "  print(' - max: %.3f' % np.max(feature_matrices[feature_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing distances\n",
    "Now, we are going to compute the distances between the items in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will try different feature vector distance metrics.\n",
    "features_distance_metrics = {\n",
    "    'euclidean': 'euclidean',  # Or lambda u, v: np.sqrt(((u-v)**2).sum()) (slower).\n",
    "    'intersection_area': lambda u, v: np.sum(np.min([u, v], 0)),  # NB: this is a similarity metric.\n",
    "    # you can expand this list with own implementation of metrics, or references to metrics in scipy\n",
    "    # (see scipy.distance.pdist reference below)\n",
    "}\n",
    "\n",
    "# Let's compute the distance matrices.\n",
    "distance_matrices = {}\n",
    "for distance_metric_name in features_distance_metrics:\n",
    "  distance_matrices[distance_metric_name] = {}\n",
    "  for feature_name in feature_extractors:\n",
    "    plot_title = 'metric: %s, feature: %s' % (feature_name, distance_metric_name)\n",
    "    print('computing distance matrix (%s)' % plot_title)\n",
    "    \n",
    "    # Compute the distance matrix using scipy.distance.pdist\n",
    "    # (see http://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.spatial.distance.pdist.html).\n",
    "    distance_matrices[distance_metric_name][feature_name] = squareform(pdist(\n",
    "        feature_matrices[feature_name], features_distance_metrics[distance_metric_name]))\n",
    "\n",
    "    # Check the size.\n",
    "    assert np.shape(distance_matrices[distance_metric_name][feature_name])[0] == number_of_images\n",
    "\n",
    "    # Plot.\n",
    "    ipynb_show_matrix(distance_matrices[distance_metric_name][feature_name], plot_title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "What do these plotted matrices indicate? What do red/blue colors indicate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now examine the distance matrices in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's use the distance matrices to find the nearest/farthest items for a number of random images.\n",
    "number_of_random_images = 2\n",
    "number_of_examples_per_image = 3\n",
    "\n",
    "# Choose random images.\n",
    "random_image_indexes = np.random.randint(0, number_of_images, number_of_random_images)\n",
    "\n",
    "# Show nearest/farthest items.\n",
    "for random_image_index in random_image_indexes:\n",
    "  _, reference_image_name = os.path.split(poster_images[random_image_index])\n",
    "  print('selected image: <%s>' % reference_image_name)\n",
    "  reference_image = cv2.imread(poster_images[random_image_index])\n",
    "  ipynb_show_cv2_image(reference_image, reference_image_name)\n",
    "  for distance_metric_name in features_distance_metrics:\n",
    "    for feature_name in feature_extractors:\n",
    "      plot_base_title = 'metric: %s, feature: %s' % (feature_name, distance_metric_name)\n",
    "      print(' - %s' % plot_base_title)\n",
    "\n",
    "      # Extract the pairwise scores for the current image.\n",
    "      pairwise_scores = distance_matrices[distance_metric_name][feature_name][random_image_index, :]\n",
    "\n",
    "      # Get the indexes sorted by score.\n",
    "      pairwise_scores_sorted_indexes = np.argsort(pairwise_scores)\n",
    "\n",
    "      # Find the top k and the bottom k images.\n",
    "      top_k_indexes = pairwise_scores_sorted_indexes[:number_of_examples_per_image]\n",
    "      bottom_k_indexes = reversed(pairwise_scores_sorted_indexes[-number_of_examples_per_image:])\n",
    "\n",
    "      # Show top k images.\n",
    "      for i, image_index in enumerate(top_k_indexes):\n",
    "        print('  top #%d: <%s>' % (i, poster_images[image_index]))\n",
    "        image = cv2.imread(poster_images[image_index])\n",
    "        ipynb_show_cv2_image(image, 'top #%d of <%s> (%s)' % (\n",
    "            i, reference_image_name, plot_base_title), figsize=(4, 4))\n",
    "        \n",
    "      # Show bottom k images.\n",
    "      for i, image_index in enumerate(bottom_k_indexes):\n",
    "        print('  bottom #%d: <%s>' % (i, poster_images[image_index]))\n",
    "        image = cv2.imread(poster_images[image_index])\n",
    "        ipynb_show_cv2_image(image, 'bottom #%d of <%s> (%s)' % (\n",
    "            i, reference_image_name, plot_base_title), figsize=(4, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "Can you explain why results end up in the top or bottom of the list?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Final Assignment\n",
    "Please play around with a few more distance metrics (and, if you are enthusiastic, a few more feature vectors--feel free to explore the possibilities of OpenCV).\n",
    "\n",
    "This mostly would require you to reconfigure parts of the code above.\n",
    "\n",
    "Then, as soon as you have a ranking you like, run the code below to generate a formatted overview of your results.\n",
    "Copy the console output into a text file, save the file as [YourName_ranking.txt], and upload this to the Dropbox link given on top of the page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate a formatted list of top-10 ranked results.\n",
    "# replace the placeholder texts below with your name and a one-line explanation of your approach.\n",
    "print 'name: %s' % 'REPLACE_THIS_WITH_YOUR_NAME'\n",
    "print 'approach: %s' % 'GIVE_A_ONE_LINE_EXPLANATION_OF_YOUR_APPROACH_HERE'\n",
    "\n",
    "# now print the top-10.\n",
    "top_k_indexes = pairwise_scores_sorted_indexes[:10]\n",
    "for i, image_index in enumerate(top_k_indexes):\n",
    "    print '%d.\\t%s' % (i, poster_images[image_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
